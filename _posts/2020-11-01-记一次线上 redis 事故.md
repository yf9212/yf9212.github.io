---
title: 记一次线上redis哨兵模式事故
tags: redis 线上事故
---

## 背景
公司服务器机房迁移，DBA重新部署Redis集群，Redis集群部署使用的sentinel哨兵模式，一master一slave三sentinel；正常的逻辑，master宕机后，能在秒级时间内拉起一个salve，升级为
master并继续对外提供服务；但实际情况是，在master的物理机宕机之后，15分钟才拉起slave成master，导致15分钟的服务不可用，造成严重的线上事故。
引起事故的原因，一方面是部署方面的失误，一方面是机房网络的不稳定，两个偶然加在一起，变成了必然。线上无小事，任何事情都不能掉以轻心。


## 技术回顾
Redis哨兵模式的高可用保障依赖哨兵对节点状态的监听，哨兵会对数据节点以及其他哨兵节点进行监控；每隔1秒，每个哨兵节点会向master、slave、其他sentinel发送一条ping 
命令做心跳检测，当某个节点超过down-after-milliseconds时间没有进行回复时，哨兵节点会对改节点做主观下线判断，在日志中会打印[+sdown]日志；
如果主观下线的节点是master,哨兵节点通过sentinel is-master-down-by-addr命令向其他sentinel节点询问对主节点状态判断，当超过quorum个sentinel节点认为master节点确实
无法访问时，sentinel会对master节点做客观下线判定，在日志中打印[+odown]日志；然后进行选举，选举出 leader 来主导从库切换超作；


选举通过Raft算法实现，每个节点都有资格成为领导者；确认master客观下线后，向其他节点发送命令要求自己设置成为领导者，收到请求的节点如果没有同意过其他sentinel节点的成为领导者
请求，则同意，否则拒绝；当同意的票数超过max(quorum,sentinels.number/2+1)时，则成为leader节点，主导主从切换；
主从切换时，选取符合条件的从节点使其变为master，其余slave监听新的master



## 哨兵集群部署拓扑图
![Image](/assets/images/project/redis-sentinel-image.jpg){:.border}
通过部署图可以看到，dba在部署的时候，为了节约成本（别问我为啥要节约成本，我也不知道！），将2个sentinel与master、slave部署在了一起，当其中部署master节点的机器宕机时，
一起部署在其中的sentinel也一起挂掉。要主从切换，必须依赖剩余2个sentinel同时判定master客观下线，才能继续接下来的leader选举和主从切换动作。如果其中任何一个sentinel
因为不可抗拒的外力导致对master节点状态判断失误，redis的高可用部署也就出现了问题。


## 线上日志分析(日志有部分删减)

#### 哨兵1日志
~~~
9311:X 29 Oct 02:35:57.926 # +sdown sentinel 50cfc0aca3c1dc85f191373139f8640444979a9f 172.*.*.138 6381 @ mymaster 172.*.*.138 6380
.
9311:X 29 Oct 02:42:00.239 # -sdown master mymaster 172.*.*.138 6380
9311:X 29 Oct 02:42:00.239 # -odown master mymaster 172.*.*.138 6380
9311:X 29 Oct 02:42:00.294 # +sdown master mymaster 172.*.*.138 6380
9311:X 29 Oct 02:42:00.294 # +odown master mymaster 172.*.*.138 6380 #quorum 1/2
9311:X 29 Oct 02:42:01.284 # -sdown master mymaster 172.*.*.138 6380
9311:X 29 Oct 02:42:01.284 # -odown master mymaster 172.*.*.138 6380
9311:X 29 Oct 02:42:01.343 # +sdown master mymaster 172.*.*.138 6380
9311:X 29 Oct 02:42:01.343 # +odown master mymaster 172.*.*.138 6380 #quorum 1/2
.
.
9311:X 29 Oct 02:46:53.032 # +sdown master mymaster 172.*.*.138 6380
9311:X 29 Oct 02:46:53.108 # +odown master mymaster 172.*.*.138 6380 #quorum 2/2
9311:X 29 Oct 02:46:53.108 # +new-epoch 1
9311:X 29 Oct 02:46:53.108 # +try-failover master mymaster 172.*.*.138 6380
9311:X 29 Oct 02:46:53.133 # +vote-for-leader 02568c0ade847a4011fd3b7a53b5713dc340ea3b 1
9311:X 29 Oct 02:46:53.136 # 299c31f6e410f7b439d102c249d1d76540a3072c voted for 02568c0ade847a4011fd3b7a53b5713dc340ea3b 1
9311:X 29 Oct 02:46:53.188 # +elected-leader master mymaster 172.*.*.138 6380
~~~
从哨兵1的日志可看到，2点35分57秒时，发现其中一台sentinel无法ping通，标记为主观下线,然后对master进行客观下线时，无法得到足够节点确认，一直无法得到主观下线的判定，一直
频繁做主客观下线判断；直到46分53秒108毫秒，对master做完客观下线判断，并且选举为master。

#### 哨兵2日志
~~~
10209:X 29 Oct 02:35:58.286 # +sdown master mymaster 172.*.*.138 6380
10209:X 29 Oct 02:35:58.286 # +sdown sentinel 50cfc0aca3c1dc85f191373139f8640444979a9f 172.*.*.138 6381 @ mymaster 172.*.*.138 6380
10209:X 29 Oct 02:46:53.137 # +new-epoch 1
10209:X 29 Oct 02:46:53.138 # +vote-for-leader 02568c0ade847a4011fd3b7a53b5713dc340ea3b 1
10209:X 29 Oct 02:46:53.252 # +odown master mymaster 172.*.*.138 6380 #quorum 2/2
10209:X 29 Oct 02:46:53.252 # Next failover delay: I will not start a failover before Thu Oct 29 02:48:53 2020
10209:X 29 Oct 02:47:05.633 # -odown master mymaster 172.*.*.138 6380
10209:X 29 Oct 02:47:27.234 # +odown master mymaster 172.*.*.138 6380 #quorum 2/2
10209:X 29 Oct 02:48:53.779 # +new-epoch 2
~~~

哨兵2日志可看出，35分58秒286毫秒的时候，哨兵对master和sentine 同时做出了主观下线判断。直到46分53秒时才完成主观下线

#### 从节点日志
~~~
10246:S 29 Oct 02:50:53.449 * Connecting to MASTER 172.*.*.138:6380
10246:S 29 Oct 02:50:53.449 * MASTER <-> SLAVE sync started
10246:S 29 Oct 02:50:53.449 # Error condition on socket for SYNC: Connection refused
10246:M 29 Oct 02:50:54.073 * Discarding previously cached master state.
10246:M 29 Oct 02:50:54.073 * MASTER MODE enabled (user request from 'id=30 addr=172.*.*.253:45305 fd=20 name= age=1747316 idle=0 flags=x db=0 sub=0 psub=0 multi=3 qbuf=0 qbuf-free=32768 obl=36 oll=0 omem=0 events=r cmd=exec')
10246:M 29 Oct 02:50:54.073 # CONFIG REWRITE executed with success.
~~~

50分53秒，连接master并启动主从同步，同时发现master无法连接。

50分54秒，leader提升为master，并且重写配置

## 结论
redis哨兵模式的部署，哨兵和数据节点不要部署在同一台物理机上，避免机器宕机引起莫名奇怪的问题。可以使用一master多slave的情况下，把slave部署3个以上，是一个不错的选择。

如果不是因为宕机时间网络也不太稳定，也不一定会导致本次事故出现。生产环境，比测试环境、UAT环境更为复杂，造成的影响也更大。

<!--more-->
---
